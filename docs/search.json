[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a driven, enthusiastic, and exceptionally skilled individual with a meticulous attention to detail and a natural aptitude for solving Finance and Statistical problems. Fueled by a genuine passion, I am eager to embark on a journey to establish my career in the fields of Statistics, Data Science, and Actuarial Science.\n\nEDUCATION\n\n\nVirginia Tech\nAugust 2023 - Current\nBlacksburg - Virginia, USA\nStatistics (PhD)\n\n\nMontana State University\nAugust 2021 - May 2023\nBozeman-Montana, USA\nMaster of Science in Statistics\n\n\nKwame Nkrumah University of Science and Technology\nOctober 2016 - September 2020\nKumasi, Ghana\nBSc. Actuarial Science\n(First Class Honors)\n\n\nAdisadel College\nOctober 2013 - May 2016\nCape Coast, Ghana\nGeneral Arts\nHigh School Diploma"
  },
  {
    "objectID": "posts/About/index.html",
    "href": "posts/About/index.html",
    "title": "My Academic Journey",
    "section": "",
    "text": "I am a young ambitious student who majored in Actuarial Science for my undergraduate studies at Kwame Nkrumah University of Science and Technology (KNUST) in Ghana and graduated with first-class honors in the department of Statistics and Actuarial science. While studying at KNUST, my first research experience was with three other colleagues to research on a project entitled “Estimating the surrender rate of life insurance policies” which had the objective of determining the surrendering rate of insurance contracts using the cox regression and survival analysis methods like the Kaplan-Meier and Nelson-Aalen estimators. The project exposed me to the fundamentals of research work and gave me the experience to prepare for advanced-level research. In line with leadership roles, I was the Chief Editor for the Actuarial Science Student Association of Ghana and was also selected to represent my school at an Annual Lady Chief Justice mentoring program held at the supreme court of Ghana. I also worked on brand advertisements by designing flyers and posters for campus events, managed social media handles for a charity group named the Christy Hope Foundation, and organized various tutorial classes for first-year statistics and mathematics students which had a great impact on their academic performance.\nMy first professional experience was an internship at Old Mutual Life Assurance Company during the summer of 2018 under the distribution support department. My duties included processing claims, processing policy amendments, and capturing new businesses. I also worked with Old Mutual Life Assurance again as a Graduate Trainee in 2020 now in charge of processing commissions for financial advisors and preparing new business reports for the company. I used software programs like Microsoft Excel and R Studio for my reports, which improved my understanding and ability to apply statistics to solve real-life problems and gave me deeper insights into how statistics and data analysis are fundamental to growth in any sector.\nI completed my Masters degree in Statistics at Montana State University, Bozeman, USA and earned an excellent pass for all the fundamental core courses (Intermediate Mathematics and Statistics, Advanced regression analysis, Linear Models, and Intermediate probability and statistics and participated in statistical consulting sections aimed at helping other graduate students and organizations with solutions on the right statistical approach for their projects and research. One project we worked on was aimed at analyzing data from survey responses for a Kinship Navigator program meant to provide support for non-parent family members raising relative children. Also, under the supervision of Dr. Ian Laga, I successfully completed a Masters thesis that focused on Bayesian Computational Methods For Latent Space Models in Networks. For the study, we examined latent space model, the type of statistical network model with the common practice of using both observed and unobserved (i.e., latent) variables in modeling an outcome in the presence or absence of network edges. The problem with estimating the parameters of the latent space model is that it can be computationally expensive when dealing with large network data. The aim was to discuss some of the existing methods for estimating the parameters of the latent space model and then use the Laplace approximation technique to estimate the parameters of this model. We then compared the Laplace approximation to the latentnet package and assessed how well they estimate the latent distances and the computational cost involved using a simulation study and then applied this new approach to a real data to see how it performs. I also worked as a Graduate Teaching Assistant at Montana State University with one year of teaching experience serving as an instructor for the Introduction to Statistics course and College Algebra. I balanced my coursework and teaching duties by taking an active part in extra-curricular activities such as participating in volunteer programs and playing a key role in the African student society at Montana State University.\nCurrently, I am a Ph.D. Statistics student at Virginia Tech and a Graduate Teaching Assistance for Statistics for social science here at the University. It is my dream to work as a Statistician and a Data Analyst and start my own statistical consulting firm. I would also love to return to my homeland some day to impact the lives of the young ones and make significant contributions to better the numerous statistical problems facing my country, Ghana."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring Knowledge and Ambitions: My Academic and Career Odyssey.",
    "section": "",
    "text": "Bayesian Computational Methods For Latent Space Models In Networks\n\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2023\n\n\nMichael Kumi\n\n\n\n\n\n\n  \n\n\n\n\nRETENTION PREDICTION FOR CAR INSURANCE\n\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2023\n\n\nMichael Kumi\n\n\n\n\n\n\n  \n\n\n\n\nMy Academic Journey\n\n\n\n\n\n\n\nAbout\n\n\n\n\n\n\n\n\n\n\n\nSep 10, 2023\n\n\nMichael Kumi\n\n\n\n\n\n\n  \n\n\n\n\nMy Interests\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 10, 2023\n\n\nMichael Kumi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "My Interests",
    "section": "",
    "text": "I’m all about the love for music and soccer, with a special place in my heart for FC Barcelona. Beyond that, I’ve explored some incredible hiking spots in Bozeman, Montana, which have added a touch of adventure to my life.\n\nThis photo was snapped during my visit to Yellowstone National Park in Montana in 2023. The scene is absolutely breathtaking. I experienced the park’s remarkable natural beauty with its colorful geysers and lush green surroundings. It’s a place where nature’s power and beauty come together in harmony. Yellowstone left a lasting impression on me, and I’m grateful for the chance to witness such a stunning landscape."
  },
  {
    "objectID": "posts/project/index.html",
    "href": "posts/project/index.html",
    "title": "Bayesian Computational Methods For Latent Space Models In Networks",
    "section": "",
    "text": "Networks are collections of interconnected things or collections of elements and their inter-relations. A network consists of the links between members of a set of actors or nodes connected by a specific kind of relationship. Networks have now been useful in studying complex systems across a diverse range of application areas. In biology, it has been useful for the study of protein-protein interactions (Pellegrini, Haynor, and Johnson (2004)). In engineering, it can be applied in electrical engineering and electronics to understand the components of electrical circuits (Kumar (2008)) and in transportation for modeling and analyzing transport networks (Tarapata (2015)). In finance, it can be used as a tool to study the relationships between market participants and their impacts on the financial market (Liang and Guo (2015)). It can be applied in Neuroscience to explore the patterns of voltage dynamics in the brain associated with epileptic seizures (Kramer and Cash (2012)) and also in the field of education to understand the patterns related to the citation of articles or journals (Newman (2004)), legal cases (Olsen and Küçüksu (2017)), and many others.\nA network structure is made up of nodes (vertices) and edges (links). Nodes represent the objects or subjects being studied, while edges represent the relationships between those objects. For example, if we investigate a social relationship between Facebook users, nodes represent users and edges represent relationships such as user friendships or group memberships. From Kolaczyk and Csárdi (2014), the mathematical structure of a network graph is defined as \\(G = (V, E)\\) which is composed of a set \\(V\\) of vertices and a set \\(E\\) of edges, with elements of \\(E\\) being unordered pairs \\({u, v}\\) of distinct vertices \\(u, v \\in V\\). The order of the graph \\(G\\) is sometimes referred to as the number of vertices \\(N_v = |V|\\) and the size as the number of edges \\(N_e = |E|\\).\nUnderstanding the structure of a network and how it came to be is very essential to network analysis. That is, we can imagine the network as the result of some underlying processes associated with the complex system of interest to us, and then ask what the most important aspects of these processes are. So we may want to know more about the actual manner in which the network was obtained, i.e., the corresponding measurement and construction process of the network. Such concerns provide an impetus for network modeling and related statistical inference tools. Some examples of statistical network models include the exponential random graph models, which are analogous to generalized linear models, stochastic block models, which are a type of mixture model, and the latent space model which can be used for a variety of purposes, for example, clustering of network data into groups with more similar characteristics (Zhou et al. (2019)).\nFor the study, we examined latent space model, the type of statistical network model with the common practice of using both observed and unobserved (i.e., latent) variables in modeling an outcome in the presence or absence of network edges. The problem with estimating the parameters of the latent space model is that it can be computationally expensive when dealing with large network data. We have a computational cost of order \\(O\\left(N^2\\right)\\) where \\(N\\) is the number of nodes or actors in the network which means that the time required to perform a particular computation increases quadratically with the size of the nodes of the network, so when we have a large network data, working with the latent space model becomes infeasible. The aim was to discuss some of the existing methods for estimating the parameters of the latent space model and then use the Laplace approximation technique to estimate the parameters of this model. We then compared the Laplace approximation to the latentnet package and assessed how well they estimate the latent distances and the computational cost involved using a simulation study and then applied this new approach to a real-data to see how it performs.\n\n\n\n\n\n\n\nReferences\n\nKolaczyk, Eric D, and Gábor Csárdi. 2014. Statistical Analysis of Network Data with r. Vol. 65. Springer.\n\n\nKramer, Mark A, and Sydney S Cash. 2012. “Epilepsy as a Disorder of Cortical Network Organization.” The Neuroscientist 18 (4): 360–72.\n\n\nKumar, K Suresh. 2008. Electric Circuits and Networks. Pearson Education India.\n\n\nLiang, Pinghan, and Shiqi Guo. 2015. “Social Interaction, Internet Access and Stock Market Participation—an Empirical Study in China.” Journal of Comparative Economics 43 (4): 883–901.\n\n\nNewman, Mark EJ. 2004. “Coauthorship Networks and Patterns of Scientific Collaboration.” Proceedings of the National Academy of Sciences 101 (suppl_1): 5200–5205.\n\n\nOlsen, Henrik Palmer, and Aysel Küçüksu. 2017. “Finding Hidden Patterns in ECtHR’s Case Law: On How Citation Network Analysis Can Improve Our Knowledge of ECtHR’s Article 14 Practice.” International Journal of Discrimination and the Law 17 (1): 4–22.\n\n\nPellegrini, Matteo, David Haynor, and Jason M Johnson. 2004. “Protein Interaction Networks.” Expert Review of Proteomics 1 (2): 239–49.\n\n\nTarapata, Zbigniew. 2015. “Modelling and Analysis of Transportation Networks Using Complex Networks: Poland Case Study.” Archives of Transport 36 (4): 55–65.\n\n\nZhou, Lei, Bai Xiao, Xianglong Liu, Jun Zhou, Edwin R Hancock, et al. 2019. “Latent Distribution Preserving Deep Subspace Clustering.” In 28th International Joint Conference on Artificial Intelligence, 4440–46. York."
  },
  {
    "objectID": "posts/project/index.html#introduction",
    "href": "posts/project/index.html#introduction",
    "title": "RETENTION PREDICTION FOR CAR INSURANCE",
    "section": "",
    "text": "Insurance is a form of a risk management contract, represented by a policy, in which the policyholder pays an insurance firm in exchange for financial security or reimbursement against uncertain losses or specific contingencies. Health, auto, life, and travel insurance are just a few of the various forms of insurance available. Auto insurance, specifically car insurance of the most prevalent types of personal insurance often required by law, that provides protection in the event that a person’s vehicle is damaged, stolen or involved in an accident. Premium, policy limit and deductibles are three crucial insurance policy elements that are frequently taken into account when picking the best insurance policy to suit an individual or an institution. For the long-term survival of an insurance company, it is important to focus on customer retention. Customer retention is a term that assesses customer loyalty, or an organization’s capacity to maintain its client over time. Many factors may influence an insurance company’s client retention rates. The research aims to understand the factors related to the retention of car insurance customers for an insurance company. We will build a model to help us understand the relationship between these factors and retention, access our model with another dataset to see how well we can predict the given response and also compare our prediction error with a null model that always predicts (Retention = 1) and results in a classification error of 0.26."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Bayesian Computational Methods For Latent Space Models In Networks",
    "section": "",
    "text": "Networks are collections of interconnected things or collections of elements and their inter-relations. A network consists of the links between members of a set of actors or nodes connected by a specific kind of relationship. Networks have now been useful in studying complex systems across a diverse range of application areas. In biology, it has been useful for the study of protein-protein interactions (Pellegrini, Haynor, and Johnson (2004)). In engineering, it can be applied in electrical engineering and electronics to understand the components of electrical circuits (Kumar (2008)) and in transportation for modeling and analyzing transport networks (Tarapata (2015)). In finance, it can be used as a tool to study the relationships between market participants and their impacts on the financial market (Liang and Guo (2015)). It can be applied in Neuroscience to explore the patterns of voltage dynamics in the brain associated with epileptic seizures (Kramer and Cash (2012)) and also in the field of education to understand the patterns related to the citation of articles or journals (Newman (2004)), legal cases (Olsen and Küçüksu (2017)), and many others.\nA network structure is made up of nodes (vertices) and edges (links). Nodes represent the objects or subjects being studied, while edges represent the relationships between those objects. For example, if we investigate a social relationship between Facebook users, nodes represent users and edges represent relationships such as user friendships or group memberships. From Kolaczyk and Csárdi (2014), the mathematical structure of a network graph is defined as \\(G = (V, E)\\) which is composed of a set \\(V\\) of vertices and a set \\(E\\) of edges, with elements of \\(E\\) being unordered pairs \\({u, v}\\) of distinct vertices \\(u, v \\in V\\). The order of the graph \\(G\\) is sometimes referred to as the number of vertices \\(N_v = |V|\\) and the size as the number of edges \\(N_e = |E|\\).\nUnderstanding the structure of a network and how it came to be is very essential to network analysis. That is, we can imagine the network as the result of some underlying processes associated with the complex system of interest to us, and then ask what the most important aspects of these processes are. So we may want to know more about the actual manner in which the network was obtained, i.e., the corresponding measurement and construction process of the network. Such concerns provide an impetus for network modeling and related statistical inference tools. Some examples of statistical network models include the exponential random graph models, which are analogous to generalized linear models, stochastic block models, which are a type of mixture model, and the latent space model which can be used for a variety of purposes, for example, clustering of network data into groups with more similar characteristics (Zhou et al. (2019)).\nFor the study, we examined latent space model, the type of statistical network model with the common practice of using both observed and unobserved (i.e., latent) variables in modeling an outcome in the presence or absence of network edges. The problem with estimating the parameters of the latent space model is that it can be computationally expensive when dealing with large network data. We have a computational cost of order \\(O\\left(N^2\\right)\\) where \\(N\\) is the number of nodes or actors in the network which means that the time required to perform a particular computation increases quadratically with the size of the nodes of the network, so when we have a large network data, working with the latent space model becomes infeasible. The aim was to discuss some of the existing methods for estimating the parameters of the latent space model and then use the Laplace approximation technique to estimate the parameters of this model. We then compared the Laplace approximation to the latentnet package and assessed how well they estimate the latent distances and the computational cost involved using a simulation study and then applied this new approach to a real-data to see how it performs.\n\n\n\n\n\n\n\nReferences\n\nKolaczyk, Eric D, and Gábor Csárdi. 2014. Statistical Analysis of Network Data with r. Vol. 65. Springer.\n\n\nKramer, Mark A, and Sydney S Cash. 2012. “Epilepsy as a Disorder of Cortical Network Organization.” The Neuroscientist 18 (4): 360–72.\n\n\nKumar, K Suresh. 2008. Electric Circuits and Networks. Pearson Education India.\n\n\nLiang, Pinghan, and Shiqi Guo. 2015. “Social Interaction, Internet Access and Stock Market Participation—an Empirical Study in China.” Journal of Comparative Economics 43 (4): 883–901.\n\n\nNewman, Mark EJ. 2004. “Coauthorship Networks and Patterns of Scientific Collaboration.” Proceedings of the National Academy of Sciences 101 (suppl_1): 5200–5205.\n\n\nOlsen, Henrik Palmer, and Aysel Küçüksu. 2017. “Finding Hidden Patterns in ECtHR’s Case Law: On How Citation Network Analysis Can Improve Our Knowledge of ECtHR’s Article 14 Practice.” International Journal of Discrimination and the Law 17 (1): 4–22.\n\n\nPellegrini, Matteo, David Haynor, and Jason M Johnson. 2004. “Protein Interaction Networks.” Expert Review of Proteomics 1 (2): 239–49.\n\n\nTarapata, Zbigniew. 2015. “Modelling and Analysis of Transportation Networks Using Complex Networks: Poland Case Study.” Archives of Transport 36 (4): 55–65.\n\n\nZhou, Lei, Bai Xiao, Xianglong Liu, Jun Zhou, Edwin R Hancock, et al. 2019. “Latent Distribution Preserving Deep Subspace Clustering.” In 28th International Joint Conference on Artificial Intelligence, 4440–46. York."
  },
  {
    "objectID": "posts/post2/index.html",
    "href": "posts/post2/index.html",
    "title": "RETENTION PREDICTION FOR CAR INSURANCE",
    "section": "",
    "text": "Insurance is a form of a risk management contract, represented by a policy, in which the policyholder pays an insurance firm in exchange for financial security or reimbursement against uncertain losses or specific contingencies. Health, auto, life, and travel insurance are just a few of the various forms of insurance available. Auto insurance, specifically car insurance of the most prevalent types of personal insurance often required by law, that provides protection in the event that a person’s vehicle is damaged, stolen or involved in an accident. Premium, policy limit and deductibles are three crucial insurance policy elements that are frequently taken into account when picking the best insurance policy to suit an individual or an institution. For the long-term survival of an insurance company, it is important to focus on customer retention. Customer retention is a term that assesses customer loyalty, or an organization’s capacity to maintain its client over time. Many factors may influence an insurance company’s client retention rates. The research aims to understand the factors related to the retention of car insurance customers for an insurance company. We will build a model to help us understand the relationship between these factors and retention, access our model with another dataset to see how well we can predict the given response and also compare our prediction error with a null model that always predicts (Retention = 1) and results in a classification error of 0.26."
  },
  {
    "objectID": "posts/post2/index.html#introduction",
    "href": "posts/post2/index.html#introduction",
    "title": "RETENTION PREDICTION FOR CAR INSURANCE",
    "section": "",
    "text": "Insurance is a form of a risk management contract, represented by a policy, in which the policyholder pays an insurance firm in exchange for financial security or reimbursement against uncertain losses or specific contingencies. Health, auto, life, and travel insurance are just a few of the various forms of insurance available. Auto insurance, specifically car insurance of the most prevalent types of personal insurance often required by law, that provides protection in the event that a person’s vehicle is damaged, stolen or involved in an accident. Premium, policy limit and deductibles are three crucial insurance policy elements that are frequently taken into account when picking the best insurance policy to suit an individual or an institution. For the long-term survival of an insurance company, it is important to focus on customer retention. Customer retention is a term that assesses customer loyalty, or an organization’s capacity to maintain its client over time. Many factors may influence an insurance company’s client retention rates. The research aims to understand the factors related to the retention of car insurance customers for an insurance company. We will build a model to help us understand the relationship between these factors and retention, access our model with another dataset to see how well we can predict the given response and also compare our prediction error with a null model that always predicts (Retention = 1) and results in a classification error of 0.26."
  },
  {
    "objectID": "posts/post2/index.html#data-overview-and-visualization",
    "href": "posts/post2/index.html#data-overview-and-visualization",
    "title": "RETENTION PREDICTION FOR CAR INSURANCE",
    "section": "DATA OVERVIEW AND VISUALIZATION",
    "text": "DATA OVERVIEW AND VISUALIZATION\nThe dataset for this project contains covariates or potential factors that could affect the retention of the car insurance policy. This section aims to create plots and graphs to help us understand the relationships that exist between the retention of the policy and the various factors that might influence this variable. The dataset contains 30,000 observations and the variables collected on the various customers can be explained with the descriptions below.\n\nAge_client: the age of the customer in years.\nAge_car: the number of years since the vehicle was bought by the customer.\nDriver2: 1 if the customer has informed the insurance company that a second occasional driver uses the vehicle, and 0 otherwise.\nClient_seniority is the number of years that the customer has been in the company.\nRetention equals 1 if the policy is renewed and 0 otherwise.\nPayment_annual 1 for annual payment and 0 for monthly payment.\n\nTo explore the dataset, we will first check the relationship between the age of the customer and the retention of the policy. From figure 1, we can see that 22,314 individuals renewed their policy and 7686 individuals did not renew their policy. Also, we observe that those who renewed their policies had an average age higher than those who did not renew their policies but on average most of the customers were in their late 50s and the spread between the groups is not so different. Figure 2 is looking at these same variables, but this is classified based on whether they have an annual payment or monthly payment. From this figure, it is interesting to see that there are some differences based on the payment method of the customer and their respective ages. People with annual payments tend to be older as compared to those who have monthly payments.\n\n\n\n\n\n\n\n\n\n\nSince we have a binary response, we can also consider the retention of the policies in terms of the probability that the client will renew their policy. Figure 2 shows a smoothing estimate using the locally estimated scatter plots smoothing of how retention changes across the different age groups based on the payment method. We can see that the proportion of policies that were renewed among young customers was higher for those with annual payments as compared to those with monthly payments making the slope for the two payment methods different. We look at this same relationship but with the client’s seniority in place of the age in figure 2. From this figure, older customers or clients who have annual payments have a higher renewal rate as compared to those with monthly installments."
  },
  {
    "objectID": "posts/post2/index.html#statistical-precedures",
    "href": "posts/post2/index.html#statistical-precedures",
    "title": "RETENTION PREDICTION FOR CAR INSURANCE",
    "section": "STATISTICAL PRECEDURES",
    "text": "STATISTICAL PRECEDURES\nFor this section, we aim at building a model to help us understand and know which variables influence or affect the retention of the car insurance policy and also derive a strategy to help us make predictions with the finalized model to help answer the research question. The first thing we can look at to guide us with which statistical model will be most appropriate is the structure of the response variable. The response variable in question has binary outcomes and this changes a lot about how the statistical analysis should be carried out. Linear regression is an additive model and would not work for binary outcomes. Therefore we will need a model that has the features of transforming the bounds of our outputs to the range of 0 and 1. The logistic regression would be appropriate for this situation. The logistic regression will treat the resulting values as probabilities which will then help us map them into random binary outcomes. We will define our logistics regression model as;\n\\[y_i\\sim Bernouli(p_i)\\] \\[Pr(y_i = 1) = p_i\\] \\[\\text{logit}(p_i) = X_i\\beta\\]\nwhere \\(y_i\\) is the response variable indicating whether or not a client will renew their policy, \\(\\text{logit}\\) is the link function, and \\(X_i\\beta\\) is our linear predictors under the assumption that the outcomes are independent given these probabilities. This next step is to discuss the variables to be included in our defined model. Looking at the provided dataset, we were given five possible factors that could influence the renewal rate of the car insurance policy. The first model we will consider will be a logistic regression model that contains all the provided independent variables as linear predictors. We will fit our models with the glm function from the stats package which is used to fit generalized linear models, specified by giving a symbolic description of the linear predictor. The generalized linear model is an extension of ordinary linear regression, where the linear model is related to the response variable via the link function.\nFor the second model, we will look at some interactions for some specific variables in addition to the model we defined as our first model. The reason why we consider interactions is that sometimes one independent variable depends on the outcome of another independent variable to explain the response. There could be situations where our response varies when an observation belongs to a specific group of another variable and influences its relationship with another explanatory variable. In this case, the slopes between these two groups under this relationship will differ making it very important to check for possible interactions and is best detected by visualizing your data with graphs. From Figure 3, we saw that there were some differences in the slope based on the payment method of the client hinting to us about possible interactions. Our proposed second model will consider an interaction between the age and the payment method, the client’s seniority and the age of the car as well as the age of the client and the age of the car. We will also consider another model with any possible interactions between all the variables in the model.\nAfter fitting the three proposed logistic regression models, we can use AIC to assess the performance of the models and aid in the model selection. The Akaike information criterion (AIC) is defined as AIC = deviance + 2k, where k is the number of coefficients in the model. The best-fit model according to AIC is the one that explains the greatest amount of variation using the fewest possible independent variables and a lower AIC value indicates a better model.\nTable 1 shows the AIC scores for the selected models and based on these values, we can say that for the given data, the best model according to the AIC is our logistic regression model which considers the interaction between the age and the payment method, the client’s seniority and the age of the car, and the age of the client and the age of the insured car. The final model is defined as;\n\\[\n\\operatorname{Pr}\\left(\\text { Retention }_i=1\\right)=p_i\n\\] \\[\n\\operatorname{logit}\\left(p_i\\right)=\\beta_0+\\beta_1 * \\text{ Age-client }_i+\\beta_2 * \\text{ Age-car }_i+\\beta_3 * \\text{ Driver1 }_i+\\beta_4 * \\text{ Payment-annual1 }_i+\n\\] \\[\n\\beta_5 * \\text{ Client-seniority }_i+\\beta_6 * \\text{ Age-client }_i * \\text{ Payment-annual1 }_i+\\beta_7 * \\text{ Age-car }_i * \\text { Client-seniority }_i+\n\\] \\[\n\\beta_8 * \\text { Age-client }_i * \\text { Age-car }_i\n\\]"
  },
  {
    "objectID": "posts/post2/index.html#results",
    "href": "posts/post2/index.html#results",
    "title": "RETENTION PREDICTION FOR CAR INSURANCE",
    "section": "RESULTS",
    "text": "RESULTS\nTable 2 is a summary of the parameter estimates from our final model together with their standard errors which is a measure of uncertainty for the coefficient. The coefficients of our model are on a logit scale and we can change them to probabilities by transforming the linear predictors of the model using the inverse logit function to get the probability that they will renew their policy (Pr(Retention = 1)). The coefficients can also be viewed in terms of the odd ratio by exponentiating our coefficients. Therefore to interpret the coefficient for the age of the client, we can say that a difference of 1 in the age of the client corresponds to a positive difference of 0.034 on a logit scale of renewing their policy and this estimate will be within the interval of 0.028 and 0.04 approximately 95% of the time. The intercept is interpreted assuming zero values for all the other continuous predictors and the reference group for the binary categorical variables and from Table 2 we have an estimate of -1.961 and a 95% confidence interval of -2.251 and -1.671 on a logit scale. For the coefficient of Payment_annual1, we can say that a client who pays annually has an expected difference of 0.436 higher with a 95% confidence interval of 0.16 and 0.712 on a logit scale of renewing their policy as compared to those of are enrolled on the monthly payment scheme. The interaction term is looking at the difference in slope on a logit scale. The coefficients of our interaction terms are almost close to zero. Meaning when we find the inverse logit, they will be also close to 0.5 representing a 50-50 chance of the customers renewing their policy hence these coefficients does not influence the probability of renewal that much. The standard errors for these coefficients are also close to 0 on a logit scale.\nFigure 5 shows a visual representation of estimates and their 95% confidence intervals for the coefficients of our selected model. The figure helps us to get a clear picture of which coefficients of the model have a higher, lower, or no impact on the retention of the car insurance policy for the insurance company on a logit scale.\n\n\n\n\n\nThe insurance also provided an additional dataset that can be used as test data to access the predictive ability of our model. We will adopt the strategy of using the covariates from this test model to predict the retention of the policies and since we know the true values, we can check how accurate our predictions are. We can use the classification error approach which tells us the number of misclassified outcomes by our model predictions out of the total number of responses to predict from the test data.\nAfter we have made predictions with our model on the test data, table 3 is the classification table for our predicted vs true values, and this results in a classification error of 0.256. This means that about 26% of the time, our model predictions for the outcomes of the test data were misspecified."
  },
  {
    "objectID": "posts/post2/index.html#discussion",
    "href": "posts/post2/index.html#discussion",
    "title": "RETENTION PREDICTION FOR CAR INSURANCE",
    "section": "DISCUSSION",
    "text": "DISCUSSION\nOur research question was to know which factors influence the retention of the insurance policy and also build a model to help us make predictions given the provided covariates. A logistic regression model was considered to model our response since we have a binary outcome of whether the clients renewed their policy or not. The final selected model based on the Akaike information criterion was an interaction model that included all our covariates and an interaction between the age and the payment method, the client’s seniority and the age of the car as well as the age of the client and the age of the car. Our model also showed that the client seniority had the greatest impact on the policy renewal compared to the other coefficients like the age of the client on a logit scale. After making predictions with this model and the additional data provided by the car insurance company, the classification error for the prediction of retention was about 0.256. Also from the research question, we want to compare our prediction error with a null model that always predicts (Retention = 1) and results in a classification error of 0.26. Table 4 represents the structure of this null model.\nUsing the null model as a basis for comparison, from table 5 we can see that our final model resulted in a classification error similar to the null model. We can use a proportion test to check if we can say our model is different from this null model in terms of the classification error. The one categorical proportion test produced a 95% confidence interval that contained the null value classification error of 0.26. Therefore we cannot say that our final selected model predicts retention differently from a null model that only predicts that a policyholder will renew their policy. Our results can only be generalized to this data from the insurance company since we don’t have a dataset from a random sample of all car insurance policies."
  },
  {
    "objectID": "posts/post2/index.html#references",
    "href": "posts/post2/index.html#references",
    "title": "RETENTION PREDICTION FOR CAR INSURANCE",
    "section": "REFERENCES",
    "text": "REFERENCES\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. Regression and other stories. Cambridge University Press, 2020.\nglm: Fitting Generalized Linear Models https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm\nViolin plot with included boxplot and sample size in ggplot2 Holtz https://r-graph-gallery.com/violin_and_boxplot_ggplot2.html\nInterpreting results from logistic regression in R using Titanic dataset Koh https://medium.com/(conankoh/interpreting-results-from-logistic-regression-in-r-using-titanic-dataset-bb9f9a1f644c?)\nLogistic regression + histogram with ggplot2 PaoloCrosettoPaoloCrosetto 58011 gold badge77 silver badges1616 bronze badges & ThierryThierry 17.9k55 gold badges4646 silver badges6565 bronze badges https://stackoverflow.com/questions/33521539/logistic-regression-histogram-with-ggplot2\nchange coefficient names in coefplot.glm() Ivo et al. https://stackoverflow.com/questions/59036723/change-coefficient-names-in-coefplot-glm"
  },
  {
    "objectID": "posts/post2/index.html#apenddix",
    "href": "posts/post2/index.html#apenddix",
    "title": "Bayesian Computational Methods For Latent Space Models In Networks",
    "section": "APENDDIX",
    "text": "APENDDIX\n\n# set up some options\nknitr::opts_chunk$set(echo = FALSE, fig.width = 5, fig.height = 5, results = \"hide\", \n                      cache = TRUE, comment = FALSE, warning = FALSE, message = FALSE, \n                      out.width = \"0.5\\\\linewidth\")\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(pander)\nlibrary(dplyr)\nlibrary(hrbrthemes)\nlibrary(viridis)\nlibrary(\"gridExtra\") \nlibrary(coefplot)\nlibrary(tinytex)\ncar_insurance &lt;- read_csv('car_insurance.csv')\n\npredict_covariates &lt;- read_csv('predict_covariates.csv')\npredict_result &lt;- read_csv('predict_result.csv')\ndata&lt;-car_insurance\ndata&lt;-data%&gt;% \n  mutate(Driver2 = factor(Driver2))%&gt;%\n  mutate(Payment_annual = factor(Payment_annual))%&gt;%\n  mutate(Retention = factor(Retention))\nsample_size &lt;- data %&gt;% group_by(Retention\n) %&gt;% summarize(num=n())\n\nplot1&lt;-data %&gt;%\n  left_join(sample_size) %&gt;%\n  mutate(myaxis = paste0(Retention, \"\\n\", \"n=\", num)) %&gt;%\n  ggplot( aes(x=myaxis, y=Age_client, fill= Retention)) +\n    geom_violin(width=1.4) +\n    geom_boxplot(width=0.1, color=\"grey\", alpha=0.2) +\n    scale_fill_viridis(discrete = TRUE) +\n  labs(x= \"\", y=\"\") +\n  theme(axis.text=element_text(size=12),axis.title=element_text(size=14,face=\"bold\"))+\n  theme_bw() + ylab(\"Retention\") + xlab(\"Age of Client\") +\n  ggtitle(\"Figure 1 -Violin plot for retention and age\")\n\n\nplot2&lt;- ggplot(data, aes(Retention, Age_client ,\n                                        fill= Payment_annual)) + \n  geom_violin() +\n  geom_boxplot(width = 0.1, size = 0.5, position = position_dodge(0.90)) +\n  labs(x= \"\", y=\"\") +\n  theme(axis.text=element_text(size=12),axis.title=element_text(size=14,face=\"bold\"))+\n  theme_bw()+ xlab(\"Retention\") + ylab(\"Age of Client\") +\nggtitle(\"Figure 2-Violin plot for retention and age\")\n\ngrid.arrange(plot1,plot2, ncol = 2) \ndf&lt;-car_insurance\ndf$Retention[df$Payment_annual == 1] &lt;- NA\ndf2&lt;-car_insurance\ndf2$Retention[df2$Payment_annual == 0] &lt;- NA\n\n\ndf&lt;-df%&gt;% \n  mutate(Payment_annual = factor(Payment_annual))\n\ndf2&lt;-df2%&gt;% \n  mutate(Payment_annual = factor(Payment_annual))\n\nplot3&lt;-df %&gt;% ggplot(aes(y = Retention, x = Age_client, color = Payment_annual))+\ngeom_smooth(formula = 'y~x', method = 'loess', color = 'red', se = F)+\ngeom_smooth(aes(x=df2$Age_client, y=df2$Retention),formula = 'y~x', \n  method = 'loess', color = 'darkslategray3', se = F)+\ngeom_rug() + \n  ggtitle('Figure 3- Retention and Age of the client') +\n  theme_bw() + xlab('Retention')+ ylab('Age of client')\n\n\nplot4&lt;-df %&gt;% ggplot(aes(y = Retention, x = Client_seniority, color = Payment_annual))+\ngeom_smooth(formula = 'y~x', method = 'loess', color = 'red', se = F)+\ngeom_smooth(aes(x=df2$Client_seniority, y=df2$Retention),formula = 'y~x', \n      method = 'loess', color = 'darkslategray3', se = F)+\ngeom_rug() + \n  ggtitle('Figure 4-Retention and Client Seniority') +\n  theme_bw() + xlab('Client Seniority')+ ylab('Retention')\ngrid.arrange(plot3, plot4, ncol = 2) \ndata&lt;-car_insurance\n\ndata&lt;-data%&gt;% \n  mutate(Driver2 = factor(Driver2))%&gt;%\n  mutate(Payment_annual = factor(Payment_annual))%&gt;%\n  mutate(Retention = factor(Retention))\nmodel1&lt;-glm(Retention~ Age_client + Age_car + Driver2 + Payment_annual + Client_seniority, \n            family = binomial(link = \"logit\"),data =  data)\n\nmodel2&lt;-glm(Retention~ Age_client + Age_car + Driver2 + Payment_annual + Client_seniority +\n              Age_client * Payment_annual + Client_seniority : Age_car + Age_client : Age_car, \n            family = binomial(link = \"logit\"),data =  data)\n\nmodel3&lt;-glm(Retention~ Age_client * Age_car * Driver2 *\n              Payment_annual * Client_seniority,\n            family = binomial(link = \"logit\"),data =  data)\na&lt;-data.frame(AIC(model1,model2,model3))\npander(a, caption = \"AIC scores for the proposed models\")\na&lt;-summary(model2)\ncof&lt;-round(a$coefficients,3)\nx&lt;-cof[2,1]\ny&lt;-cof[2,2]\npander(cof, caption = \"Summary of coeffcients from our final model\")\ncoefplot(model2, CI = 2, color = \"blue\")+ theme_bw() + xlab('x')+ ylab('y')+\n  geom_point(color = \"red\")+ \n  ggtitle(\n    'Figure 5- Coefficient plot showing the 95% confidence interval for our estimated parameters')\npredict_covariates &lt;- read_csv('predict_covariates.csv')\npredict_covariates&lt;-predict_covariates%&gt;% \n  mutate(Driver2 = factor(Driver2))%&gt;%\n  mutate(Payment_annual = factor(Payment_annual))\n\npredict_result &lt;- read_csv('predict_result.csv')\npredict_result&lt;-predict_result%&gt;% \n  mutate(Retention = factor(Retention))\n\n\np&lt;-(predict(model3, predict_covariates, type=\"response\"))\np&lt;-data.frame(p)\npred&lt;-pred1&lt;-ifelse(p&gt;0.5,1,0)\npred&lt;-data.frame(pred)\npred&lt;-setNames(pred,c(\"pred\"))\ntab&lt;- table(pred = pred$pred, true = predict_result$Retention)\ntab&lt;-data.frame(tab)\npander(tab, caption = \"Classification table for our predicted response and the true values\")\nclassification_error &lt;- 1- sum(pred$pred == predict_result$Retention)/length(pred$pred)\n#classification_error for logistic regression\nglm_model&lt;-round(classification_error,3)\n\nnull&lt;-data.frame(cbind(rep(exp(500)/(1+exp(500)), length(pred1))))\nnull&lt;-setNames(null, \"pred\")\ntab&lt;- table(pred = null$pred, true = predict_result$Retention)\ntab&lt;-data.frame(tab)\npander(tab, caption= \"Classification table for null model\")\n\n\nclassification_error &lt;- 1- sum(null$pred == predict_result$Retention)/length(null$pred)\n#classification_error for logistic regression\nnull_model&lt;-round(classification_error,2)\n\nclassification_error&lt;-data.frame(glm_model,null_model)\n\npander(classification_error, caption = \"Classification error for the two models\" )\na&lt;-prop.test(2323, 9084, p = 0.26,\n          alternative = c(\"two.sided\"),\n          conf.level = 0.95)\nb&lt;-data.frame(a$conf.int)\nlower&lt;-b$a.conf.int[1]\nupper&lt;-b$a.conf.int[2]\nc&lt;-data.frame(lower,upper)\npander(c, caption = \"Confidence interval from the proportion test\")\nlibrary(report)\nlibrary(dplyr)\ncite_packages()"
  },
  {
    "objectID": "posts/post2/index.html#packages",
    "href": "posts/post2/index.html#packages",
    "title": "Bayesian Computational Methods For Latent Space Models In Networks",
    "section": "PACKAGES",
    "text": "PACKAGES\n\n\nAuguie B (2017). gridExtra: Miscellaneous Functions for “Grid” Graphics. R package version 2.3, https://CRAN.R-project.org/package=gridExtra.\nDaróczi G, Tsegelskyi R (2022). pander: An R ‘Pandoc’ Writer. R package version 0.6.5, https://CRAN.R-project.org/package=pander.\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, Pedro A, Sciaini, Marco, Scherer, Cédric (2023). viridis(Lite) - Colorblind-Friendly Color Maps for R. doi:10.5281/zenodo.4678327 https://doi.org/10.5281/zenodo.4678327, viridisLite package version 0.4.2, https://sjmgarnier.github.io/viridis/.\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, Pedro A, Sciaini, Marco, Scherer, Cédric (2023). viridis(Lite) - Colorblind-Friendly Color Maps for R. doi:10.5281/zenodo.4679423 https://doi.org/10.5281/zenodo.4679423, viridis package version 0.6.4, https://sjmgarnier.github.io/viridis/.\nGrolemund G, Wickham H (2011). “Dates and Times Made Easy with lubridate.” Journal of Statistical Software, 40(3), 1-25. https://www.jstatsoft.org/v40/i03/.\nLander JP (2022). coefplot: Plots Coefficients from Fitted Models. R package version 1.2.8, https://CRAN.R-project.org/package=coefplot.\nMakowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023). “Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.” CRAN. https://easystats.github.io/report/.\nMüller K, Wickham H (2023). tibble: Simple Data Frames. R package version 3.2.1, https://CRAN.R-project.org/package=tibble.\nR Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/.\nRudis B (2020). hrbrthemes: Additional Themes, Theme Components and Utilities for ‘ggplot2’. R package version 0.8.0, https://CRAN.R-project.org/package=hrbrthemes.\nWickham H (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ISBN 978-3-319-24277-4, https://ggplot2.tidyverse.org.\nWickham H (2022). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.5.0, https://CRAN.R-project.org/package=stringr.\nWickham H (2023). forcats: Tools for Working with Categorical Variables (Factors). R package version 1.0.0, https://CRAN.R-project.org/package=forcats.\nWickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686 https://doi.org/10.21105/joss.01686.\nWickham H, François R, Henry L, Müller K, Vaughan D (2023). dplyr: A Grammar of Data Manipulation. R package version 1.1.2, https://CRAN.R-project.org/package=dplyr.\nWickham H, Henry L (2023). purrr: Functional Programming Tools. R package version 1.0.2, https://CRAN.R-project.org/package=purrr.\nWickham H, Hester J, Bryan J (2023). readr: Read Rectangular Text Data. R package version 2.1.4, https://CRAN.R-project.org/package=readr.\nWickham H, Vaughan D, Girlich M (2023). tidyr: Tidy Messy Data. R package version 1.3.0, https://CRAN.R-project.org/package=tidyr.\nXie Y (2023). tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents. R package version 0.46, https://github.com/rstudio/tinytex. Xie Y (2019). “TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.” TUGboat, 40(1), 30-32. https://tug.org/TUGboat/Contents/contents40-1.html."
  }
]